<!DOCTYPE HTML PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head>
<!-- Generated by Apache Maven Doxia at Oct 2, 2012 -->

  
    <title>Hadoop MapReduce Next Generation 2.0.2-alpha - Setting up a Single Node Cluster.</title>
    
      </head><body>
       
    <div id="bodyColumn">
      <div id="contentBox">
        <div class="section"><h2>Hadoop MapReduce Next Generation - Setting up a Single Node Cluster.<a name="Hadoop_MapReduce_Next_Generation_-_Setting_up_a_Single_Node_Cluster."></a></h2><p></p><ul><li><a href="#Hadoop_MapReduce_Next_Generation_-_Setting_up_a_Single_Node_Cluster.">Hadoop MapReduce Next Generation - Setting up a Single Node Cluster.</a><ul><li><a href="#Mapreduce_Tarball">Mapreduce Tarball</a></li><li><a href="#Setting_up_the_environment.">Setting up the environment.</a></li><li><a href="#Setting_up_Configuration.">Setting up Configuration.</a><ul><li><a href="#Setting_up_mapred-site.xml">Setting up mapred-site.xml</a></li><li><a href="#Setting_up_yarn-site.xml">Setting up yarn-site.xml</a></li></ul></li></ul></li></ul><div class="section"><h3>Prerequisites</h3><p>Flavor of Linux (I was using ubuntu) and Java 1.6</p><h3>Mapreduce Tarball<a name="Mapreduce_Tarball"></a></h3><p>You
 should be able to obtain the MapReduce tarball from the release. If 
not, you should be able to create a tarball from the source.</p><div class="source"><pre>$ mvn clean install -DskipTests
$ cd hadoop-mapreduce-project
$ mvn clean install assembly:assembly -Pnative</pre></div><p><b>NOTE:</b> You will need protoc installed of version 2.4.1 or greater.</p><p>To ignore the native builds in mapreduce you can omit the <tt>-Pnative</tt> argument for maven. The tarball should be available in <tt>target/</tt> directory. </p></div><div class="section"><h3>Setting up the environment.<a name="Setting_up_the_environment."></a></h3><p>Add following lines to .bashrc</p><pre>export HADOOP_YARN_HOME=/home/neeraj/hadoop-2.0.2-alpha
export HADOOP_MAPRED_HOME=/home/neeraj/hadoop-2.0.2-alpha</pre><p>Add following to $HADOOP_YARN_HOME/etc/hadoop/yarn-env.sh. $HADOOP_CONF_DIR is already setup in hadoop-2.0.2-alpha</p><pre>export HADOOP_COMMON_HOME="${HADOOP_COMMON_HOME:-$HADOOP_YARN_HOME}"
export HADOOP_HDFS_HOME="${HADOOP_HDFS_HOME:-$HADOOP_YARN_HOME}"</pre><p>Assuming you have installed hadoop-common/hadoop-hdfs and exported <b>$HADOOP_COMMON_HOME</b>/<b>$HADOOP_HDFS_HOME</b>, untar hadoop mapreduce tarball and set environment variable <b>$HADOOP_MAPRED_HOME</b> to the untarred directory. Set <b>$HADOOP_YARN_HOME</b> the same as <b>$HADOOP_MAPRED_HOME</b>. </p><p><b>NOTE:</b> The following instructions assume you have hdfs running. If not then do the following:</p><p>Add following lines to $HADOOP_YARN_HOME/etc/hadoop/core-site.xml</p><pre>&lt;property&gt;
    &lt;name&gt;fs.default.name&lt;/name&gt;
    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
  &lt;/property&gt;
</pre><p>Create the following directories:</p><pre>mkdir /home/neeraj/yarn2_data
mkdir /home/neeraj/yarn2_data/hdfs
mkdir /home/neeraj/yarn2_data/hdfs/namenode
mkdir /home/neeraj/yarn2_data/hdfs/datanode</pre><p>Add following lines to $HADOOP_YARN_HOME/etc/hadoop/hdfs-site.xml</p><pre>&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;1&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
    &lt;value&gt;file:/home/neeraj/yarn2_data/hdfs/namenode&lt;/value&gt;
  &lt;/property&gt;
  &lt;property&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
    &lt;value&gt;file:/home/neeraj/yarn2_data/hdfs/datanode&lt;/value&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre><p>Format Namenode</p><pre>$HADOOP_YARN_HOME/bin/hadoop namenode -format</pre></div><div class="section"><h3>Setting up Configuration.<a name="Setting_up_Configuration."></a></h3><p>To
 start the ResourceManager and NodeManager, you will have to update the 
configs. Assuming your $HADOOP_CONF_DIR is the configuration directory 
and has the installed configs for HDFS and <tt>core-site.xml</tt>. There are 2 config files you will have to setup <tt>mapred-site.xml</tt> and <tt>yarn-site.xml</tt>.</p><div class="section"><h4>Setting up <tt>mapred-site.xml</tt><a name="Setting_up_mapred-site.xml"></a></h4><p>Add the following configs to your <tt>mapred-site.xml</tt>.</p><div class="source"><pre>  &lt;property&gt;
    &lt;name&gt;mapreduce.cluster.temp.dir&lt;/name&gt;
    &lt;value&gt;&lt;/value&gt;
    &lt;description&gt;No description&lt;/description&gt;
    &lt;final&gt;true&lt;/final&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;mapreduce.cluster.local.dir&lt;/name&gt;
    &lt;value&gt;&lt;/value&gt;
    &lt;description&gt;No description&lt;/description&gt;
    &lt;final&gt;true&lt;/final&gt;
  &lt;/property&gt;</pre><p>I was getting Heap out of space error which went away on adding this additional property to mapred-site.xml</p><pre>&lt;property&gt;
  &lt;name&gt;mapreduce.task.io.sort.mb&lt;/name&gt;
  &lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
</pre></div></div><div class="section"><h4>Setting up <tt>yarn-site.xml</tt><a name="Setting_up_yarn-site.xml"></a></h4></div></div></div><div class="section"><h2>Add the following configs to your <tt>yarn-site.xml</tt><a name="Add_the_following_configs_to_your_yarn-site.xml"></a></h2><div class="source"><pre>  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
    &lt;value&gt;localhost:8025&lt;/value&gt;
    &lt;description&gt;host is the hostname of the resource manager and 
    port is the port on which the NodeManagers contact the Resource Manager.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
    &lt;value&gt;localhost:8030&lt;/value&gt;
    &lt;description&gt;host is the hostname of the resourcemanager and port is the port
    on which the Applications in the cluster talk to the Resource Manager.
    &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;
    &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler&lt;/value&gt;
    &lt;description&gt;In case you do not want to use the default scheduler&lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
    &lt;value&gt;localhost:8035&lt;/value&gt;
    &lt;description&gt;the host is the hostname of the ResourceManager and the port is the port on
    which the clients can talk to the Resource Manager. &lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;
    &lt;value&gt;&lt;/value&gt;
    &lt;description&gt;the local directories used by the nodemanager&lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.address&lt;/name&gt;
    &lt;value&gt;0.0.0.0:8041&lt;/value&gt;
    &lt;description&gt;the nodemanagers bind to this port&lt;/description&gt;
  &lt;/property&gt;  

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;
    &lt;value&gt;10240&lt;/value&gt;
    &lt;description&gt;the amount of memory on the NodeManager in GB&lt;/description&gt;
  &lt;/property&gt;
 
  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;
    &lt;value&gt;/app-logs&lt;/value&gt;
    &lt;description&gt;directory on hdfs where the application logs are moved to &lt;/description&gt;
  &lt;/property&gt;

   &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;
    &lt;value&gt;&lt;/value&gt;
    &lt;description&gt;the directories used by Nodemanagers as log directories&lt;/description&gt;
  &lt;/property&gt;

  &lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce.shuffle&lt;/value&gt;
    &lt;description&gt;shuffle service that needs to be set for Map Reduce to run &lt;/description&gt;
  &lt;/property&gt;</pre></div><div class="section"><h3>Setting up <tt>capacity-scheduler.xml</tt><a name="Setting_up_capacity-scheduler.xml"></a></h3><p>Make sure you populate the root queues in <tt>capacity-scheduler.xml</tt>.You may of to create this file if not present.</p><div class="source"><pre>  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.capacity.root.queues&lt;/name&gt;
    &lt;value&gt;unfunded,default&lt;/value&gt;
  &lt;/property&gt;
  
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.capacity.root.capacity&lt;/name&gt;
    &lt;value&gt;100&lt;/value&gt;
  &lt;/property&gt;
  
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.capacity.root.unfunded.capacity&lt;/name&gt;
    &lt;value&gt;50&lt;/value&gt;
  &lt;/property&gt;
  
  &lt;property&gt;
    &lt;name&gt;yarn.scheduler.capacity.root.default.capacity&lt;/name&gt;
    &lt;value&gt;50&lt;/value&gt;
  &lt;/property&gt;</pre></div></div><div class="section"><h3>Running daemons.<a name="Running_daemons."></a></h3><p>Assuming that the environment variables <b>$HADOOP_COMMON_HOME</b>, <b>$HADOOP_HDFS_HOME</b>, <b>$HADOO_MAPRED_HOME</b>, <b>$HADOOP_YARN_HOME</b>, <b>$JAVA_HOME</b> and <b>$HADOOP_CONF_DIR</b> have been set appropriately. Set $<b>$YARN_CONF_DIR</b> the same as $<b>HADOOP_CONF_DIR</b></p><p>Run HDFS daemons in three different Terminal windows</p><pre>cd $HADOOP_YARN_HOME
bin/hdfs namnode
bin/hdfs secondarynamenode
bin/hdfs datanode</pre><p>Run ResourceManager and NodeManager as:</p><div class="source"><pre>$ cd $HADOOP_MAPRED_HOME
$ sbin/yarn-daemon.sh start resourcemanager
$ sbin/yarn-daemon.sh start nodemanager</pre></div><p>You should be up and running. You can run randomwriter as (be sure you have 10GB of disk space):</p><div class="source"><pre>$ $HADOOP_COMMON_HOME/bin/hadoop jar $HADOOP_YARN_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.2-alpha.jar randomwriter out
$ $HADOOP_COMMON_HOME/bin/hadoop jar $HADOOP_YARN_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.2-alpha.jar pi 2 10</pre></div></div></div><div class="section"><h2>Good luck.<a name="Good_luck."></a></h2></div>
      </div>
    </div>
    </div>
  </body></html>
